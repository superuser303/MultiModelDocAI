{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f3aac2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install pytesseract transformers datasets torch diffusers google-colab\n",
    "!apt-get install tesseract-ocr\n",
    "\n",
    "# Import libraries\n",
    "import os\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from google.colab import drive\n",
    "import io\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "OUTPUT_DIR = '/content/drive/MyDrive/MultiModalDocAI/processed'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Load dataset via API\n",
    "try:\n",
    "    dataset = load_dataset('rvl-cdip', split='train[:1000]')  # Stream 1000 samples\n",
    "    print('Dataset loaded successfully.')\n",
    "except Exception as e:\n",
    "    print(f'Error loading dataset: {e}')\n",
    "    raise SystemExit\n",
    "\n",
    "# OCR function\n",
    "def extract_text(image):\n",
    "    try:\n",
    "        text = pytesseract.image_to_string(image)\n",
    "        return text if text.strip() else 'No text extracted'\n",
    "    except Exception as e:\n",
    "        print(f'OCR error: {e}')\n",
    "        return 'OCR failed'\n",
    "\n",
    "# Generate synthetic document images\n",
    "def generate_synthetic_image(prompt='invoice document with text'):\n",
    "    try:\n",
    "        pipe = StableDiffusionPipeline.from_pretrained('stabilityai/stable-diffusion-2-1', torch_dtype=torch.float16)\n",
    "        pipe = pipe.to('cuda')\n",
    "        image = pipe(prompt).images[0]\n",
    "        synthetic_path = os.path.join(OUTPUT_DIR, f'synthetic_{prompt.replace(' ', '_')}.png')\n",
    "        image.save(synthetic_path)\n",
    "        return synthetic_path, image\n",
    "    except Exception as e:\n",
    "        print(f'Synthetic image generation error: {e}')\n",
    "        return None, None\n",
    "\n",
    "# Preprocess streamed data\n",
    "processed_data = []\n",
    "for idx, item in enumerate(dataset):\n",
    "    try:\n",
    "        image = Image.open(io.BytesIO(item['image']))  # Stream image from memory\n",
    "        label = item['label']\n",
    "        \n",
    "        # Extract text\n",
    "        text = extract_text(image)\n",
    "        \n",
    "        # Generate synthetic image\n",
    "        synthetic_path, synthetic_image = generate_synthetic_image()\n",
    "        synthetic_text = extract_text(synthetic_image) if synthetic_image else 'No synthetic text'\n",
    "        \n",
    "        # Store in memory\n",
    "        processed_data.append({\n",
    "            'image_id': idx,\n",
    "            'text': text,\n",
    "            'label': label,\n",
    "            'synthetic_image_path': synthetic_path if synthetic_path else 'None',\n",
    "            'synthetic_text': synthetic_text\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f'Error processing sample {idx}: {e}')\n",
    "        continue\n",
    "\n",
    "# Save to CSV in Google Drive\n",
    "if processed_data:\n",
    "    df = pd.DataFrame(processed_data)\n",
    "    df.to_csv(os.path.join(OUTPUT_DIR, 'processed_data.csv'), index=False)\n",
    "    print(f'Preprocessing complete. Data saved to {OUTPUT_DIR}')\n",
    "else:\n",
    "    print('No data processed. Check dataset access or preprocessing steps.')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
