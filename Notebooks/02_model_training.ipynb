{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9c1904",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install transformers datasets torch google-colab\n",
    "!apt-get install tesseract-ocr\n",
    "\n",
    "# Import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from transformers import AutoProcessor, AutoModelForDocumentClassification\n",
    "from google.colab import drive\n",
    "import io\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "OUTPUT_DIR = '/content/drive/MyDrive/MultiModalDocAI/processed'\n",
    "MODEL_DIR = '/content/drive/MyDrive/MultiModalDocAI/models'\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "# Load dataset for image streaming\n",
    "try:\n",
    "    dataset = load_dataset('rvl-cdip', split='train[:1000]')  # Stream 1000 samples\n",
    "    print('Dataset loaded successfully.')\n",
    "except Exception as e:\n",
    "    print(f'Error loading dataset: {e}')\n",
    "    raise SystemExit\n",
    "\n",
    "# Fine-tune DiT\n",
    "try:\n",
    "    processor = AutoProcessor.from_pretrained('microsoft/dit-base-finetuned-rvlcdip')\n",
    "    model = AutoModelForDocumentClassification.from_pretrained('microsoft/dit-base-finetuned-rvlcdip', num_labels=16)\n",
    "    model.to('cuda')\n",
    "    \n",
    "    # Load processed data\n",
    "    df = pd.read_csv(os.path.join(OUTPUT_DIR, 'processed_data.csv'))\n",
    "    \n",
    "    # Training loop\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "    model.train()\n",
    "    for idx, row in df.iterrows():\n",
    "        try:\n",
    "            image = Image.open(io.BytesIO(dataset[int(row['image_id'])]['image']))  # Stream image\n",
    "            encoding = processor(image, return_tensors='pt', truncation=True, padding='max_length')\n",
    "            encoding = {k: v.to('cuda') for k, v in encoding.items()}\n",
    "            labels = torch.tensor([row['label']]).to('cuda')\n",
    "            \n",
    "            outputs = model(**encoding, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            if idx % 100 == 0:\n",
    "                print(f'Sample {idx}, Loss: {loss.item()}')\n",
    "                torch.cuda.empty_cache()  # Free memory\n",
    "        except Exception as e:\n",
    "            print(f'Training error at sample {idx}: {e}')\n",
    "            continue\n",
    "    \n",
    "    # Save model to Google Drive\n",
    "    model.save_pretrained(os.path.join(MODEL_DIR, 'dit_model'))\n",
    "    processor.save_pretrained(os.path.join(MODEL_DIR, 'dit_processor'))\n",
    "    print(f'Model saved to {MODEL_DIR}')\n",
    "except Exception as e:\n",
    "    print(f'Training error: {e}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
